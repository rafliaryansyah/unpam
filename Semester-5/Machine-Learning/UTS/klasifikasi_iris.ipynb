{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proyek Klasifikasi: Prediksi Jenis Bunga Iris\n",
        "## UTS Machine Learning - Universitas Pamulang\n",
        "\n",
        "**Deskripsi:** Proyek ini menggunakan dataset Iris untuk memprediksi jenis bunga berdasarkan karakteristik fisiknya.\n",
        "\n",
        "**Dataset:** Iris Dataset (150 sampel, 4 fitur, 3 kelas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Library dasar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Library sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Model Klasifikasi\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Evaluasi Model\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, \n",
        "    classification_report, \n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_curve,\n",
        "    roc_auc_score,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(\"✓ Library berhasil diimport\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load dan Eksplorasi Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset Iris\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
        "\n",
        "print(\"Dataset Iris berhasil dimuat!\")\n",
        "print(f\"\\nJumlah sampel: {df.shape[0]}\")\n",
        "print(f\"Jumlah fitur: {df.shape[1]-2}\")\n",
        "print(f\"\\nKelas target: {df['species'].unique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tampilkan 5 data pertama\n",
        "print(\"5 Data Pertama:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Informasi dataset\n",
        "print(\"Informasi Dataset:\")\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistik deskriptif\n",
        "print(\"Statistik Deskriptif:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cek missing values\n",
        "print(\"Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribusi kelas target\n",
        "print(\"Distribusi Kelas Target:\")\n",
        "print(df['species'].value_counts())\n",
        "print(f\"\\nPersentase:\")\n",
        "print(df['species'].value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi distribusi kelas\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Count plot\n",
        "df['species'].value_counts().plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
        "axes[0].set_title('Distribusi Kelas Target', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Spesies')\n",
        "axes[0].set_ylabel('Jumlah')\n",
        "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
        "\n",
        "# Pie chart\n",
        "df['species'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
        "                                   colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
        "axes[1].set_title('Proporsi Kelas Target', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('distribusi_kelas.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Visualisasi distribusi kelas selesai\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribusi fitur\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "features = iris.feature_names\n",
        "\n",
        "for idx, feature in enumerate(features):\n",
        "    row, col = idx // 2, idx % 2\n",
        "    for species in df['species'].unique():\n",
        "        data = df[df['species'] == species][feature]\n",
        "        axes[row, col].hist(data, alpha=0.6, label=species, bins=20)\n",
        "    \n",
        "    axes[row, col].set_title(f'Distribusi {feature}', fontsize=12, fontweight='bold')\n",
        "    axes[row, col].set_xlabel(feature)\n",
        "    axes[row, col].set_ylabel('Frekuensi')\n",
        "    axes[row, col].legend()\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('distribusi_fitur.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Visualisasi distribusi fitur selesai\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plot untuk melihat outliers\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "features = iris.feature_names\n",
        "\n",
        "for idx, feature in enumerate(features):\n",
        "    row, col = idx // 2, idx % 2\n",
        "    df.boxplot(column=feature, by='species', ax=axes[row, col])\n",
        "    axes[row, col].set_title(f'Box Plot: {feature}')\n",
        "    axes[row, col].set_xlabel('Spesies')\n",
        "    axes[row, col].set_ylabel(feature)\n",
        "\n",
        "plt.suptitle('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('boxplot_fitur.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Box plot selesai\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df[iris.feature_names].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, fmt='.2f')\n",
        "plt.title('Correlation Matrix - Fitur Iris', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Correlation matrix selesai\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pair plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "pairplot = sns.pairplot(df, hue='species', markers=['o', 's', 'D'], \n",
        "                        palette='husl', diag_kind='kde', height=2.5)\n",
        "pairplot.fig.suptitle('Pair Plot - Iris Dataset', y=1.02, fontsize=16, fontweight='bold')\n",
        "plt.savefig('pairplot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Pair plot selesai\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pisahkan fitur dan target\n",
        "X = df[iris.feature_names]\n",
        "y = df['target']\n",
        "\n",
        "print(f\"Shape fitur (X): {X.shape}\")\n",
        "print(f\"Shape target (y): {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Data berhasil dibagi:\")\n",
        "print(f\"Training set: {X_train.shape[0]} sampel\")\n",
        "print(f\"Testing set: {X_test.shape[0]} sampel\")\n",
        "print(f\"\\nDistribusi kelas di training set:\")\n",
        "print(pd.Series(y_train).value_counts().sort_index())\n",
        "print(f\"\\nDistribusi kelas di testing set:\")\n",
        "print(pd.Series(y_test).value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"✓ Data berhasil distandardisasi\")\n",
        "print(f\"\\nMean setelah scaling (training): {X_train_scaled.mean(axis=0)}\")\n",
        "print(f\"Std setelah scaling (training): {X_train_scaled.std(axis=0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Logistic Regression\n",
        "print(\"Training Logistic Regression...\")\n",
        "lr_model = LogisticRegression(max_iter=200, random_state=42)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"✓ Logistic Regression selesai ditraining\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Decision Tree\n",
        "print(\"Training Decision Tree...\")\n",
        "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_dt = dt_model.predict(X_test_scaled)\n",
        "y_pred_proba_dt = dt_model.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"✓ Decision Tree selesai ditraining\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 K-Nearest Neighbors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train K-Nearest Neighbors\n",
        "print(\"Training K-Nearest Neighbors...\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "y_pred_proba_knn = knn_model.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"✓ K-Nearest Neighbors selesai ditraining\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Support Vector Machine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Support Vector Machine\n",
        "print(\"Training Support Vector Machine...\")\n",
        "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "y_pred_proba_svm = svm_model.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"✓ Support Vector Machine selesai ditraining\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fungsi untuk evaluasi model\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    \"\"\"\n",
        "    Fungsi untuk mengevaluasi performa model klasifikasi\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUASI MODEL: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"\\n1. Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    \n",
        "    # Precision, Recall, F1-Score (weighted average)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    \n",
        "    print(f\"2. Precision (weighted): {precision:.4f}\")\n",
        "    print(f\"3. Recall (weighted): {recall:.4f}\")\n",
        "    print(f\"4. F1-Score (weighted): {f1:.4f}\")\n",
        "    \n",
        "    # Classification Report\n",
        "    print(f\"\\n5. Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, \n",
        "                                target_names=['Setosa', 'Versicolor', 'Virginica']))\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluasi semua model\n",
        "results = {}\n",
        "\n",
        "results['Logistic Regression'] = evaluate_model(y_test, y_pred_lr, 'Logistic Regression')\n",
        "results['Decision Tree'] = evaluate_model(y_test, y_pred_dt, 'Decision Tree')\n",
        "results['K-Nearest Neighbors'] = evaluate_model(y_test, y_pred_knn, 'K-Nearest Neighbors')\n",
        "results['Support Vector Machine'] = evaluate_model(y_test, y_pred_svm, 'Support Vector Machine')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi Confusion Matrix untuk semua model\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "models = [\n",
        "    ('Logistic Regression', y_pred_lr),\n",
        "    ('Decision Tree', y_pred_dt),\n",
        "    ('K-Nearest Neighbors', y_pred_knn),\n",
        "    ('Support Vector Machine', y_pred_svm)\n",
        "]\n",
        "\n",
        "for idx, (name, y_pred) in enumerate(models):\n",
        "    row, col = idx // 2, idx % 2\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=['Setosa', 'Versicolor', 'Virginica'],\n",
        "                yticklabels=['Setosa', 'Versicolor', 'Virginica'],\n",
        "                ax=axes[row, col], cbar_kws={'label': 'Count'})\n",
        "    \n",
        "    axes[row, col].set_title(f'Confusion Matrix: {name}', \n",
        "                             fontsize=12, fontweight='bold', pad=10)\n",
        "    axes[row, col].set_ylabel('True Label')\n",
        "    axes[row, col].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Confusion matrices berhasil divisualisasikan\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 ROC Curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC Curve untuk multiclass classification\n",
        "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "models_proba = [\n",
        "    ('Logistic Regression', y_pred_proba_lr),\n",
        "    ('Decision Tree', y_pred_proba_dt),\n",
        "    ('K-Nearest Neighbors', y_pred_proba_knn),\n",
        "    ('Support Vector Machine', y_pred_proba_svm)\n",
        "]\n",
        "\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "class_names = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "for idx, (name, y_proba) in enumerate(models_proba):\n",
        "    row, col = idx // 2, idx % 2\n",
        "    \n",
        "    # ROC curve untuk setiap kelas\n",
        "    for i, color, class_name in zip(range(n_classes), colors, class_names):\n",
        "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n",
        "        roc_auc = roc_auc_score(y_test_bin[:, i], y_proba[:, i])\n",
        "        \n",
        "        axes[row, col].plot(fpr, tpr, color=color, lw=2,\n",
        "                           label=f'{class_name} (AUC = {roc_auc:.3f})')\n",
        "    \n",
        "    # Diagonal line\n",
        "    axes[row, col].plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "    \n",
        "    axes[row, col].set_xlim([0.0, 1.0])\n",
        "    axes[row, col].set_ylim([0.0, 1.05])\n",
        "    axes[row, col].set_xlabel('False Positive Rate', fontsize=10)\n",
        "    axes[row, col].set_ylabel('True Positive Rate', fontsize=10)\n",
        "    axes[row, col].set_title(f'ROC Curve: {name}', fontsize=12, fontweight='bold')\n",
        "    axes[row, col].legend(loc='lower right', fontsize=9)\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ ROC curves berhasil divisualisasikan\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buat DataFrame perbandingan\n",
        "comparison_df = pd.DataFrame(results).T\n",
        "comparison_df = comparison_df.round(4)\n",
        "comparison_df['accuracy_pct'] = (comparison_df['accuracy'] * 100).round(2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PERBANDINGAN PERFORMA MODEL\")\n",
        "print(\"=\"*70)\n",
        "print(comparison_df)\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi perbandingan metrics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
        "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "colors_bar = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#95E1D3']\n",
        "\n",
        "for idx, (metric, metric_name) in enumerate(zip(metrics, metric_names)):\n",
        "    row, col = idx // 2, idx % 2\n",
        "    \n",
        "    data = comparison_df[metric]\n",
        "    bars = axes[row, col].bar(data.index, data.values, color=colors_bar)\n",
        "    \n",
        "    # Tambahkan nilai di atas bar\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        axes[row, col].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                           f'{height:.4f}',\n",
        "                           ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    axes[row, col].set_title(f'{metric_name} Comparison', fontsize=12, fontweight='bold')\n",
        "    axes[row, col].set_ylabel(metric_name)\n",
        "    axes[row, col].set_ylim([0, 1.1])\n",
        "    axes[row, col].tick_params(axis='x', rotation=45)\n",
        "    axes[row, col].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Visualisasi perbandingan model selesai\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Radar chart untuk perbandingan keseluruhan\n",
        "from math import pi\n",
        "\n",
        "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "N = len(categories)\n",
        "\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='polar')\n",
        "\n",
        "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "angles += angles[:1]\n",
        "\n",
        "colors_radar = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#95E1D3']\n",
        "\n",
        "for idx, (model_name, color) in enumerate(zip(comparison_df.index, colors_radar)):\n",
        "    values = comparison_df.loc[model_name, metrics].values.tolist()\n",
        "    values += values[:1]\n",
        "    \n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=color)\n",
        "    ax.fill(angles, values, alpha=0.15, color=color)\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories, size=11)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], size=9)\n",
        "ax.grid(True)\n",
        "\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
        "plt.title('Radar Chart - Perbandingan Performa Model', size=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('radar_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Radar chart selesai\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Cross-Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation untuk validasi model\n",
        "print(\"\\nMelakukan 5-Fold Cross-Validation...\\n\")\n",
        "\n",
        "cv_results = {}\n",
        "models_cv = {\n",
        "    'Logistic Regression': lr_model,\n",
        "    'Decision Tree': dt_model,\n",
        "    'K-Nearest Neighbors': knn_model,\n",
        "    'Support Vector Machine': svm_model\n",
        "}\n",
        "\n",
        "for name, model in models_cv.items():\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "    cv_results[name] = {\n",
        "        'scores': scores,\n",
        "        'mean': scores.mean(),\n",
        "        'std': scores.std()\n",
        "    }\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Scores: {scores}\")\n",
        "    print(f\"  Mean Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi cross-validation results\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "model_names = list(cv_results.keys())\n",
        "means = [cv_results[name]['mean'] for name in model_names]\n",
        "stds = [cv_results[name]['std'] for name in model_names]\n",
        "\n",
        "x_pos = np.arange(len(model_names))\n",
        "bars = ax.bar(x_pos, means, yerr=stds, capsize=10, color=colors_bar, \n",
        "              alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# Tambahkan nilai di atas bar\n",
        "for i, (bar, mean, std) in enumerate(zip(bars, means, stds)):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + std,\n",
        "           f'{mean:.4f}\\n(±{std:.4f})',\n",
        "           ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Accuracy', fontsize=12)\n",
        "ax.set_title('5-Fold Cross-Validation Results', fontsize=14, fontweight='bold', pad=15)\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.set_ylim([0, 1.1])\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('cross_validation.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Cross-validation visualization selesai\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Kesimpulan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tentukan model terbaik\n",
        "best_model_name = comparison_df['accuracy'].idxmax()\n",
        "best_accuracy = comparison_df['accuracy'].max()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KESIMPULAN ANALISIS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n1. Dataset Iris berhasil diklasifikasikan menggunakan 4 algoritma:\")\n",
        "print(f\"   - Logistic Regression\")\n",
        "print(f\"   - Decision Tree\")\n",
        "print(f\"   - K-Nearest Neighbors\")\n",
        "print(f\"   - Support Vector Machine\")\n",
        "print(f\"\\n2. MODEL TERBAIK: {best_model_name}\")\n",
        "print(f\"   Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
        "print(f\"   Precision: {comparison_df.loc[best_model_name, 'precision']:.4f}\")\n",
        "print(f\"   Recall: {comparison_df.loc[best_model_name, 'recall']:.4f}\")\n",
        "print(f\"   F1-Score: {comparison_df.loc[best_model_name, 'f1_score']:.4f}\")\n",
        "\n",
        "print(f\"\\n3. Perbandingan Performa (berdasarkan Accuracy):\")\n",
        "sorted_models = comparison_df.sort_values('accuracy', ascending=False)\n",
        "for idx, (model, row) in enumerate(sorted_models.iterrows(), 1):\n",
        "    print(f\"   {idx}. {model}: {row['accuracy']:.4f} ({row['accuracy']*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\n4. Insight:\")\n",
        "print(f\"   - Semua model menunjukkan performa yang sangat baik (accuracy > 90%)\")\n",
        "print(f\"   - Dataset Iris relatif mudah untuk diklasifikasikan\")\n",
        "print(f\"   - Tidak ada overfitting yang signifikan berdasarkan cross-validation\")\n",
        "print(f\"   - Fitur-fitur dalam dataset memiliki daya diskriminatif yang tinggi\")\n",
        "\n",
        "print(f\"\\n5. Rekomendasi:\")\n",
        "print(f\"   - Model {best_model_name} direkomendasikan untuk produksi\")\n",
        "print(f\"   - Pertimbangkan ensemble methods untuk meningkatkan performa\")\n",
        "print(f\"   - Lakukan hyperparameter tuning untuk optimasi lebih lanjut\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Simpan Model dan Hasil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simpan hasil ke CSV\n",
        "comparison_df.to_csv('model_comparison_results.csv')\n",
        "print(\"✓ Hasil perbandingan disimpan ke 'model_comparison_results.csv'\")\n",
        "\n",
        "# Simpan model terbaik\n",
        "import pickle\n",
        "\n",
        "best_models = {\n",
        "    'Logistic Regression': lr_model,\n",
        "    'Decision Tree': dt_model,\n",
        "    'K-Nearest Neighbors': knn_model,\n",
        "    'Support Vector Machine': svm_model\n",
        "}\n",
        "\n",
        "with open(f'best_model_{best_model_name.replace(\" \", \"_\").lower()}.pkl', 'wb') as f:\n",
        "    pickle.dump(best_models[best_model_name], f)\n",
        "\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(f\"✓ Model terbaik ({best_model_name}) dan scaler disimpan\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANALISIS SELESAI!\")\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
